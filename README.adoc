// INSTRUCTION: Please remove all comments that start INSTRUCTION prior to commit. Most comments should be removed, although not the copyright.
// INSTRUCTION: The copyright statement must appear at the top of the file
//
// Copyright (c) 2017 IBM Corporation and others.
// Licensed under Creative Commons Attribution-NoDerivatives
// 4.0 International (CC BY-ND 4.0)
//   https://creativecommons.org/licenses/by-nd/4.0/
//
// Contributors:
//     IBM Corporation
//
:projectid: istio
:page-layout: guide
:page-duration: 15 minutes
:page-releasedate: 2018-06-30
:page-description: Explore how to route traffic to different versions of the same service using Istio and Kubernetes.
:page-tags: ['microservices', 'Kubernetes', 'Docker', 'containers', 'kubectl', 'Minikube', 'Istio']
:page-permalink: /guides/{projectid}
:page-related-guides: ['docker', 'kubernetes']
:common-includes: https://raw.githubusercontent.com/OpenLiberty/guides-common/master
:source-highlighter: prettify
:page-seo-title: Istio routing tutorial
:page-seo-description: How to run microservices in Istio
= Versioning services with Istio

[.hidden]
NOTE: This repository contains the guide documentation source. To view the guide in published form, view it on the https://openliberty.io/guides/{projectid}.html[Open Liberty website].

Explore how to leverage content-based routing to route HTTP traffic to different versions of the same service using Istio and Kubernetes.

:kube: Kubernetes
:istio: Istio
:win: WINDOWS
:mac: MAC
:linux: LINUX


== What you'll learn

You will learn how to deploy an application to a Kubernetes cluster and enable {istio} on it. You will also learn how to configure
{istio} to route http requests based on the uri and content of the headers.

The two microservices that you will deploy are called `inventory` and `system`. The `inventory` service stores information about systems that are running the `system` service.
The `system` service retrieves system properties about the system that it is running on. Specifically, it retrieves
the hostname, username, and operating system.

You will use Minikube as your local {kube} cluster. You will use {istio}'s Ingress, and the `kubectl`
CLI tool to deploy your application as well as configure the routing.

=== What is {istio}?

{istio} is a platform for managing how microservices interact with each other as well as the outside world.
It works by deploying istio control plane and injecting an additional container into each of your pods that contains
the https://www.envoyproxy.io/[Envoy] proxy. You can think of Envoy as a sidecar that intercepts and controls all the traffic to and from your container. It is specialized for a service mesh architecture since it offers useful features
such as load balancing and support for distributed tracing.

While {istio} supports {kube} and that will be the focus of this guide, note that {istio}
can also be used with other environments such as Docker Compose. {istio} has many features, some of them are
request routing, access control, distributed tracing. The focus of this guide will be request routing.

=== Why {istio}?

{istio} provides a collection of features that allow you to manage several aspects of your services
such as: Routing, Telemetry, and Security. These features can be easily configured independently of your
application's code.

A possible use case for {istio}'s Telemetry feature can be to enable distributed tracing which allows you
to visualize how HTTP requests travel between different services in your cluster using a tool such as https://zipkin.io/[Zipkin].
One of the items {istio} offers under its collection of security features is to enable HTTPS between pods
in your cluster to secure communication internally.

The use case for {istio} which will be covered in this guide is that it can be used to route between
two different versions of an application. One other reason to use {istio} is that it can be used to enable
https between pods.

// =================================================================================================
// Prerequisites
// =================================================================================================

include::{common-includes}/kube-prereq.adoc[]

// =================================================================================================
// Getting Started
// =================================================================================================

include::{common-includes}/gitclone.adoc[]

// no "try what you'll build" section in this guide since it would be too long due to all setup the user will have to do.

// =================================================================================================
// Staring and preparing your cluster for deployment
// =================================================================================================

:minikube-start: minikube start --memory=8192 --cpus=4 --kubernetes-version=v1.10.0
include::{common-includes}/kube-start.adoc[]

// =================================================================================================
// Deploying Istio
// =================================================================================================

== Deploying Istio

First, go to the https://github.com/istio/istio/releases[{istio} release page] and download the latest stable release. Extract the archive and navigate to the directory containing the extracted files. Add the `bin/` directory to your `PATH`.

Next, deploy the {istio} custom resource definitions. Custom resource definitions allows {istio} to define custom {kube} resources that you can use in your resource definition files.

```
kubectl apply -f install/kubernetes/helm/istio/templates/crds.yaml
```

Next, deploy {istio}'s resources to your cluster by running the `kubectl apply` command, which creates or updates
{kube} resources defined in a yaml file. This command will deploy {istio}.

```
kubectl apply -f install/kubernetes/istio-demo.yaml
```

Verify that {istio} was successfully deployed. All the values in the `AVAILABLE` column will have a value of `1` once
the deployment is complete.

```
kubectl get deployments -n istio-system
```
 
Ensure that the istio deployments are all available before continuing, it may take a few minutes for all of them to be available.
[source, role="no_copy"]
----
NAME                     DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
grafana                  1         1         1            1           44s
istio-citadel            1         1         1            1           44s
istio-egressgateway      1         1         1            1           44s
istio-galley             1         1         1            1           44s
istio-ingressgateway     1         1         1            1           44s
istio-pilot              1         1         1            1           44s
istio-policy             1         1         1            1           44s
istio-sidecar-injector   1         1         1            1           44s
istio-telemetry          1         1         1            1           44s
istio-tracing            1         1         1            1           43s
prometheus               1         1         1            1           44s
servicegraph             1         1         1            1           44s
----

// =================================================================================================
// Deploying v1 of the services to cluster
// =================================================================================================

== Deploying version 1 of the services to the cluster

Navigate to the `start` directory and run the following command, it may take a few minutes to build.
It will build the application and then package it into two docker images, one for each service.
To build the docker images it uses a maven plugin called `dockerfile-maven-plugin`.

```
mvn clean package
```

After running the command, it builds a docker image for the `inventory` service and an image for the `system` service.
You can verify that these images were created by running the given command. 

```
docker images
```

You will see images called `inventory-service:1.0-SNAPSHOT` and `system-service:1.0-SNAPSHOT` listed in a table
similar to the output.

[source, role="no_copy"]
----
REPOSITORY                                 TAG                 IMAGE ID            CREATED             SIZE
inventory-service                          1.0-SNAPSHOT        d316c2c2c6ba        9 seconds ago       501MB
system-service                             1.0-SNAPSHOT        5f48add7c0da        30 seconds ago      501MB
istio/galley                               1.0.1               7ac6c7be3d3e        5 days ago          65.8MB
istio/citadel                              1.0.1               abcc721c2454        5 days ago          51.7MB
istio/mixer                                1.0.1               0d97b4000ed5        5 days ago          64.5MB
istio/sidecar_injector                     1.0.1               a122adc160b7        5 days ago          45.3MB
istio/proxyv2                              1.0.1               f1bf7b920fe1        5 days ago          352MB
istio/pilot                                1.0.1               46d3b4e95fc3        5 days ago          290MB
open-liberty                               latest              ed1ca62c4bd5        7 days ago          501MB
prom/prometheus                            v2.3.1              b82ef1f3aa07        2 months ago        119MB
----

To deploy the `inventory` and `system` services to the {kube} cluster, run the command:

```
istioctl kube-inject -f inventory-app.yaml | kubectl apply -f -
```

You can see that your resources are created:

[source, role="no_copy"]
----
gateway.networking.istio.io/inventory-gateway created
service/inventory-service created
deployment.apps/inventory-deployment-v1 created
service/system-service created
deployment.apps/system-deployment created
----

Next deploy the virtual service for the `inventory` and `system` service. A virtual service defines how requests are routed to your applications through the gateway.

```
kubectl apply -f routing.yaml
```

The `routing.yaml` configuration file contains configuration for a virtual service resource, it specifies that requests to `/inventory` be forwarded to the `inventory` service and requests to `/system` are forwarded to the `system` service. Similarly to `inventory-app.yaml` you can see the results of the `kubectl apply -f ...` command for `routing.yaml`:

[source, role="no_copy"]
----
virtualservice.networking.istio.io/inventory-virtual-service created
----

Once all the deployments are available, you should be able to navigate to make a request to `\http://<ip-address>:<port>/inventory/systems` to view
v1 of the deployed application, as defined in `inventory-app.yaml` the gateway is expecting the host to be `my-inventory.com` so ensure to set the `Host` header appropriately.

You can check that all of the deployments are available using the command.

```
kubectl get deployments
```

Which produces a list of deployments for your microservices.

[source, role="no_copy"]
----
NAME                      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
inventory-deployment-v1   1         1         1            1           1m
system-deployment         1         1         1            1           1m
----

****
[system]#*{win} | {mac}*#

Make a request to the service by using curl or https://www.getpostman.com/[Postman] if curl is unavailable.

```
curl -HHost:my-inventory.com http://localhost/inventory/systems
```

[system]#*{linux}*#

Make a request to the service by using curl.

```
curl -HHost:my-inventory.com http://`minikube ip`:31380/inventory/systems
```
****

// =================================================================================================
// Modify the service
// =================================================================================================

== Modify and deploy version 2 of the service

If you make a breaking change to your REST api, existing clients may be broken. This is particularly an issue if your API is public
for anyone to use. Typically you will want a way to keep existing clients working as intended, while new clients use the updated API.
To simulate this scenario, you will introduce a breaking change to the `inventory` service and then redeploy it to the
kubernetes cluster as `v2`.

Rename the `getTotal()` method in `inventory/src/main/java/io/openliberty/guides/inventory/model/InventoryList.java` to `getCount()`.

[source, Java]
----
include::finish/inventory/src/main/java/io/openliberty/guides/inventory/model/InventoryList.java[tags=**;!copyright;]
----

Renaming this method will introduce a breaking change to the REST service because the response will have renamed properties after deployment.
Any client using your service will be expecting to see a property called `total`, but sometimes they'll see `count` instead.
This is not good for your API's consumers since the response would be somewhat unpredictable from their end.

Before version 2 is deployed, the `/inventory/systems` endpoint responds with a JSON in the form:

[source, role="no_copy"]
----
{
    "systems": [],
    "total": 0
}
----

After version 2 is deployed, the same endpoint can respond with JSON in the form:

[source, role="no_copy"]
----
{
    "systems": [],
    "count": 0
}
----


Therefore, any clients consuming the updated service will be broken since they are expecting a property called
`total` instead of `count`. Instead of running only the new service, both services can be run simultaneously.
The reason behind running both services is so that old clients do not have to upgrade to use the new api,
they can simply continue to use the old one. For example, if someone has created a frontend for the `inventory` service
and the frontend expects to receive a response in the form of `v1` but gets a response in the form of `v2` then issues can arise.
To mitigate this you can run both versions simultaneously and route requests appropriately to the relevant version, therefore
you avoid breaking existing clients.

Run this command to update the version of your service.
```
mvn versions:set -DnewVersion=2.0-SNAPSHOT
```

Navigate to the `start/inventory` directory and run the given command to rebuild the `inventory` service.
```
mvn clean package
```

Update the `inventory-app.yaml` file to add a new deployment `inventory-deployment-v2`.
Adding a new deployment under the same service with no additional configuration means that it will be load balanced and
requests will be sent to both deployments.


[source, yaml]
----
include::finish/inventory-app.yaml[tags=**]
----

Notice the `version` labels used to denote which deployment is for version 1 of the application and
which deployment is for version 2. This will give us the ability to select which version of the `inventory`
service to forward requests to.


Redeploy your services using the same command from before.

```
istioctl kube-inject -f inventory-app.yaml | kubectl apply -f -
```

You can see that version 2 of the `inventory` application has been deployed.
[source, role="no_copy"]
----
gateway.networking.istio.io/inventory-gateway unchanged
service/inventory-service unchanged
deployment.apps/inventory-deployment-v1 unchanged
deployment.apps/inventory-deployment-v2 created
service/system-service unchanged
deployment.apps/system-deployment unchanged
----

****
[system]#*{win} | {mac}*#

Make a few requests to the service by using curl or https://www.getpostman.com/[Postman] if curl is unavailable.

```
curl -HHost:my-inventory.com http://localhost/inventory/systems
```

[system]#*{linux}*#

Make a few requests to the service by using curl.

```
curl -HHost:my-inventory.com http://`minikube ip`:31380/inventory/systems
```
****


Observe that requests go to both v1 and v2. This is not what
a client consuming this service wants because it is unpredictable and the client would get
an incorrect response half of the time. To solve this you can use request routing to default
to version 1 and allow the client to access version 2 when specifically requested. This way,
existing client won't be broken and any new clients that would like to use v2 can easily
request it.


// =================================================================================================
// Configuring request routing
// =================================================================================================

== Configuring request routing

To solve the issue where the requests are forwarded seemingly at random, you'll configure request
routing and apply the configuration to your cluster.

Replace the `routing.yaml` file in the `start` directory:

[source, yaml]
----
include::finish/routing.yaml[tags=**;]
----

The `routing.yaml` file routes incoming requests based on the uri prefix `/inventory` and an HTTP header
`x-version`. The header is used to identify which version of the `inventory` service that the client would like
the requests to go to. If the header has the value `v2`, then requests will be routed to the `v2` deployment and otherwise
the requests are routed to `v1` to avoid breaking existing clients. In the `inventory-app.yaml` file some `version` labels are specified,
in the `routing.yaml` file the `version` label is used to route requests to the appropriate
deployment.

Apply the routing rules you created in the `routing.yaml` file by running the given command.
```
kubectl apply -f routing.yaml
```

****
[system]#*{win} | {mac}*#

Make a request to the service by using curl or https://www.getpostman.com/[Postman] if curl is unavailable.

```
curl -HHost:my-inventory.com http://localhost/inventory/systems -Hx-version:v2
curl -HHost:my-inventory.com http://localhost/inventory/systems
```

[system]#*{linux}*#

Make a request to the service by using curl.

```
curl -HHost:my-inventory.com http://`minikube ip`:31380/inventory/systems -Hx-version:v2
curl -HHost:my-inventory.com http://`minikube ip`:31380/inventory/systems
```
****

Observe that requests with the `v2` header are routed to version 2 of the inventory microservice and requests without the header are routed to version 1 of the microservice.

With the help of {istio} you now have request routing configured to direct requests appropriately to the correct
version of an application. This is just one of the many uses for {istio}, and it solves the versioning issue
in a convenient way that requires no code changes on the developer's part.

== Testing microservices that are running on {kube}

A few tests are provided to check that the two `inventory` versions have been deployed correctly and that request
routing has been correctly configured. If the tests fail, then you may have made a mistake at one of the steps.

Create the inventory version test in the `inventory/src/test/java/it/io/openliberty/guides/inventory/InventoryVersionTest.java` file:
[source, Java]
----
include::finish/inventory/src/test/java/it/io/openliberty/guides/inventory/InventoryVersionTest.java[tags=**;!copyright;!doc]
----

The `testV1Default` test case verifies that if no `x-version` header is present, then it defaults to version 1.
Similarly the `testV1Header` test case verifies that requests are routed to version v1 if the `x-version` header
has a value of `v1`. The final test case `testV2Header` checks that requests are routed to version v2 when
the `x-version` header is set to `v2`.

Each test is repeated three times to ensure that it didn't pass by chance if the routing was not applied correctly.
If the routing rules are not applied, then on some requests you will see `v1` and on other requests you will see `v2`.
This is why the tests need to be run multiple times.

****
[system]#*{win} | {mac}*#

Run the command to start the tests:

```
mvn verify -Ddockerfile.skip=true -Dtest.ip=localhost -Dtest.port=80
```

[system]#*{linux}*#

Run the command to start the tests:

```
mvn verify -Ddockerfile.skip=true -Dtest.ip=`minikube ip` -Dtest.port=31380
```
****

The `dockerfile.skip=true` flag skips re-building the docker images. The `test.ip` and `test.port`
parameters refer to the ip address and port for the {istio} gateway.

If the tests pass, then you should see output similar to this:

[source, role="no_copy"]
----
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running it.io.openliberty.guides.inventory.InventoryVersionTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.98 sec - [ ] in it.io.openliberty.guides.inventory.InventoryVersionTest

Results :

Tests run: 3, Failures: 0, Errors: 0, Skipped: 0
----


== Tearing down your environment

Finally, you may want to teardown all the deployed resources as a cleanup step.

Delete your resources from the cluster.
```
kubectl delete -f inventory-app.yaml
kubectl delete -f routing.yaml
```

Navigate to the directory where you extracted {istio} and delete the {istio} resources from the cluster.
```
kubectl delete -f install/kubernetes/istio-demo.yaml
kubectl delete -f install/kubernetes/helm/istio/templates/crds.yaml
```

include::{common-includes}/kube-minikube-teardown.adoc[]

// =================================================================================================
// finish
// =================================================================================================

== Great work! You're done!

You have just deployed two microservice to a Kubernetes cluster and created routing rules to route between two different version of one of the microservice using Istio.

// uncomment this when Istio guide is released
//Feel free to check out our https://github.com/OpenLiberty/guide-istio[Istio guide], which builds on top of what you learned here.

// Include the below from the guides-common repo to tell users how they can contribute to the guide
include::{common-includes}/finish.adoc[]

// DO NO CREATE ANYMORE SECTIONS AT THIS POINT
// Related guides will be added in automatically here if you included them in ":page-related-guides"
